{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo3xtscDO2ox"
      },
      "source": [
        "## SISA MODEL DEMO CODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1NvVQwdMK9o",
        "outputId": "e07097cd-304a-4149-89d5-9b856b788185"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d93b2f64610>"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time\n",
        "from copy import deepcopy\n",
        "import torch\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset link : https://www.kaggle.com/datasets/dhruvpanchal1/cat-dog-classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg5p62JVSznt"
      },
      "source": [
        "# Load training data (50 cat, 50 dog)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "id": "sho5tZVIStnH",
        "outputId": "8e99eb4c-8162-496a-f2aa-e096aaefee26"
      },
      "outputs": [],
      "source": [
        "train_dir = \"/home/dhruv/Documents/AML_/cat_dog_images/train\"\n",
        "test_dir = \"/home/dhruv/Documents/AML_/cat_dog_images/test\"\n",
        "cat_train_dir = os.path.join(train_dir, \"cat\")\n",
        "dog_train_dir = os.path.join(train_dir, \"dog\")\n",
        "cat_test_dir = os.path.join(test_dir, \"cat\")\n",
        "dog_test_dir = os.path.join(test_dir, \"dog\")\n",
        "\n",
        "# Image preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "def load_images(directory, label, is_train=True, max_images=50):\n",
        "    X, y, image_paths = [], [], []\n",
        "    folder = os.path.join(directory, \"cats\" if label == 1 else \"dogs\")\n",
        "    for img_name in sorted(os.listdir(folder))[:max_images if is_train else 10]:\n",
        "        img_path = os.path.join(folder, img_name)\n",
        "        img = Image.open(img_path).convert(\"RGB\")\n",
        "        img_tensor = transform(img).unsqueeze(0)\n",
        "        X.append(img_tensor)\n",
        "        y.append(label)\n",
        "        image_paths.append(img_path)\n",
        "    return X, y, image_paths\n",
        "\n",
        "cat_X, cat_y, cat_paths = load_images(train_dir, 1)\n",
        "dog_X, dog_y, dog_paths = load_images(train_dir, 0)\n",
        "X_train_tensors = torch.cat(cat_X + dog_X)\n",
        "y_train = np.array(cat_y + dog_y)\n",
        "train_paths = cat_paths + dog_paths\n",
        "\n",
        "# Shuffle training data to ensure mixed classes\n",
        "indices = np.arange(len(y_train))\n",
        "np.random.shuffle(indices)\n",
        "X_train_tensors = X_train_tensors[indices]\n",
        "y_train = y_train[indices]\n",
        "train_paths = [train_paths[i] for i in indices]\n",
        "\n",
        "# Load test data (10 cat, 10 dog)\n",
        "cat_X_test, cat_y_test, cat_test_paths = load_images(test_dir, 1, is_train=False)\n",
        "dog_X_test, dog_y_test, dog_test_paths = load_images(test_dir, 0, is_train=False)\n",
        "X_test_tensors = torch.cat(cat_X_test + dog_X_test)\n",
        "y_test = np.array(cat_y_test + dog_y_test)\n",
        "test_paths = cat_test_paths + dog_test_paths\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZRsLMYPVIlK"
      },
      "source": [
        "# Feature extraction with ResNet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VD5rh3gGVHNP"
      },
      "outputs": [],
      "source": [
        "resnet = models.resnet18(pretrained=True)\n",
        "resnet.eval()\n",
        "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "feature_extractor.to(device)\n",
        "\n",
        "def extract_features(X):\n",
        "    with torch.no_grad():\n",
        "        X = X.to(device)\n",
        "        features = feature_extractor(X).squeeze(-1).squeeze(-1).cpu().numpy()\n",
        "    return features\n",
        "\n",
        "\n",
        "X_train = extract_features(X_train_tensors)\n",
        "X_test = extract_features(X_test_tensors)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6xHFAUGVTkx"
      },
      "source": [
        "# Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_zmf-6E2VQma"
      },
      "outputs": [],
      "source": [
        "def train_model(X, y, model=None):\n",
        "    if model is None:\n",
        "        model = LogisticRegression(random_state=42)\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Skip fitting if only one class\n",
        "    if len(np.unique(y)) < 2:\n",
        "        return model, time.time() - start_time\n",
        "    model.fit(X, y)\n",
        "    \n",
        "    return model, time.time() - start_time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4g1GLyUWYpn_"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Pwz1vYuMYrOu",
        "outputId": "e91e5443-f345-4436-ef8a-e30e2b4a34b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Baseline training time: 0.003 seconds\n",
            "Baseline test accuracy: 0.950\n"
          ]
        }
      ],
      "source": [
        "baseline_model, baseline_time = train_model(X_train, y_train)\n",
        "baseline_acc = accuracy_score(y_test, baseline_model.predict(X_test))\n",
        "print(f\"Baseline training time: {baseline_time:.3f} seconds\")\n",
        "print(f\"Baseline test accuracy: {baseline_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtOSwIQLZMNi"
      },
      "source": [
        "# Naive Unlearning Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "3Y_nlE0HZKdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Removing image: /home/dhruv/Documents/AML_/cat_dog_images/train/cats/cats_5.jpg\n",
            "Naive unlearning time (retrain all): 0.001 seconds\n",
            "Naive unlearning test accuracy: 0.950\n"
          ]
        }
      ],
      "source": [
        "# Remove image #5 (index 4)\n",
        "remove_idx = 4\n",
        "print(f\"Removing image: {train_paths[remove_idx]}\")\n",
        "X_naive = np.delete(X_train, remove_idx, axis=0)\n",
        "y_naive = np.delete(y_train, remove_idx)\n",
        "naive_model, naive_time = train_model(X_naive, y_naive)\n",
        "naive_acc = accuracy_score(y_test, naive_model.predict(X_test))\n",
        "print(f\"Naive unlearning time (retrain all): {naive_time:.3f} seconds\")\n",
        "print(f\"Naive unlearning test accuracy: {naive_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sCTlnNRaa7k"
      },
      "source": [
        "# SISA Unlearning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "_muKM-VFMEMj",
        "outputId": "ff42f88f-c7c4-4ba1-b137-a92ba2be9495"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SISA baseline test accuracy: 0.750\n"
          ]
        }
      ],
      "source": [
        "## Defining the parameter\n",
        "n_shards = 5\n",
        "n_slices_per_shard = 4\n",
        "samples_per_shard = len(X_train) // n_shards  # 20 images\n",
        "samples_per_slice = samples_per_shard // n_slices_per_shard  # 5 images\n",
        "\n",
        "## Aggregation step\n",
        "def aggregate_predictions(models, X):\n",
        "    predictions = np.array([model.predict(X) for model in models])\n",
        "    return np.apply_along_axis(lambda x: np.bincount(x).argmax(), axis=0, arr=predictions)\n",
        "\n",
        "\n",
        "# Sharding\n",
        "shards = []\n",
        "for i in range(n_shards):\n",
        "    start = i * samples_per_shard\n",
        "    end = start + samples_per_shard\n",
        "    shards.append((X_train[start:end], y_train[start:end]))\n",
        "\n",
        "\n",
        "# Isolation & Slicing\n",
        "sub_models = []\n",
        "checkpoints = []\n",
        "for shard_X, shard_y in shards:\n",
        "    model = LogisticRegression(random_state=42)\n",
        "    shard_checkpoints = []\n",
        "    for slice_idx in range(n_slices_per_shard):\n",
        "        slice_start = slice_idx * samples_per_slice\n",
        "        slice_end = slice_start + samples_per_slice\n",
        "        slice_X = shard_X[slice_start:slice_end]\n",
        "        slice_y = shard_y[slice_start:slice_end]\n",
        "        model, _ = train_model(slice_X, slice_y, model)\n",
        "        shard_checkpoints.append(deepcopy(model))\n",
        "    sub_models.append(model)\n",
        "    checkpoints.append(shard_checkpoints)\n",
        "\n",
        "\n",
        "# Baseline SISA evaluation\n",
        "sisa_predictions = aggregate_predictions(sub_models, X_test)\n",
        "sisa_acc = accuracy_score(y_test, sisa_predictions)\n",
        "print(f\"SISA baseline test accuracy: {sisa_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-yQll-Em0lE"
      },
      "source": [
        "# SISA Unlearning Demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "biJ5wrXEMKIj"
      },
      "outputs": [],
      "source": [
        "# SISA Unlearning: Remove image #5\n",
        "start_time = time.time()\n",
        "photo_shard = remove_idx // samples_per_shard  # Shard 0\n",
        "photo_slice = (remove_idx % samples_per_shard) // samples_per_slice  # Slice 0\n",
        "photo_local_idx = remove_idx % samples_per_slice  # Local index 4\n",
        "\n",
        "# Retrain affected shard\n",
        "shard_X, shard_y = shards[photo_shard]\n",
        "slice_start = photo_slice * samples_per_slice\n",
        "slice_end = slice_start + samples_per_slice\n",
        "slice_X = np.delete(shard_X[slice_start:slice_end], photo_local_idx, axis=0)\n",
        "slice_y = np.delete(shard_y[slice_start:slice_end], photo_local_idx)\n",
        "\n",
        "# Start from checkpoint or fresh model\n",
        "model = deepcopy(checkpoints[photo_shard][photo_slice - 1]) if photo_slice > 0 else LogisticRegression(random_state=42)\n",
        "model, _ = train_model(slice_X, slice_y, model)\n",
        "\n",
        "# Continue remaining slices\n",
        "for slice_idx in range(photo_slice + 1, n_slices_per_shard):\n",
        "    slice_start = slice_idx * samples_per_slice\n",
        "    slice_end = slice_start + samples_per_slice\n",
        "    slice_X = shard_X[slice_start:slice_end]\n",
        "    slice_y = shard_y[slice_start:slice_end]\n",
        "    model, _ = train_model(slice_X, slice_y, model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TW1O9FConIok"
      },
      "source": [
        "# Update sub-models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Yvf__12bnIAK"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "SISA unlearning time (retrain shard 0, slice 0+): 0.013 seconds\n",
            "SISA unlearning test accuracy: 0.750\n"
          ]
        }
      ],
      "source": [
        "sub_models[photo_shard] = model\n",
        "sisa_unlearn_time = time.time() - start_time\n",
        "sisa_unlearn_predictions = aggregate_predictions(sub_models, X_test)\n",
        "sisa_unlearn_acc = accuracy_score(y_test, sisa_unlearn_predictions)\n",
        "print(f\"SISA unlearning time (retrain shard {photo_shard}, slice {photo_slice}+): {sisa_unlearn_time:.3f} seconds\")\n",
        "print(f\"SISA unlearning test accuracy: {sisa_unlearn_acc:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O7-CbjbHnFBw"
      },
      "source": [
        "# Sample predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "vxj5XqrZnD8Z"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample predictions on test images ([Dog, Cat]):\n",
            "Test images: ['/home/dhruv/Documents/AML_/cat_dog_images/test/cats/cat_1.jpg', '/home/dhruv/Documents/AML_/cat_dog_images/test/dogs/dog_1.jpg']\n",
            "Naive Unlearning: [1 0] (0=dog, 1=cat)\n",
            "SISA Unlearning: [1 0] (0=dog, 1=cat)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nSample predictions on test images ([Dog, Cat]):\")\n",
        "sample_test_idx = [0, 10]  # First dog, first cat\n",
        "sample_X_test = X_test[sample_test_idx]\n",
        "sample_y_test = y_test[sample_test_idx]\n",
        "sample_paths = [test_paths[i] for i in sample_test_idx]\n",
        "naive_preds = naive_model.predict(sample_X_test)\n",
        "sisa_preds = aggregate_predictions(sub_models, sample_X_test)\n",
        "print(f\"Test images: {sample_paths}\")\n",
        "print(f\"Naive Unlearning: {naive_preds} (0=dog, 1=cat)\")\n",
        "print(f\"SISA Unlearning: {sisa_preds} (0=dog, 1=cat)\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "solar_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
